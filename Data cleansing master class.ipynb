{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.848\n"
     ]
    }
   ],
   "source": [
    "# naive approach to normalizing the data before splitting the data and evaluating the model\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# standardize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# fit the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.3f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.455\n"
     ]
    }
   ],
   "source": [
    "# correct approach for normalizing the data after the data is split before the model is evaluated\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# define the scaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(X_train)\n",
    "# scale the training dataset\n",
    "X_train = scaler.transform(X_train)\n",
    "# scale the test dataset\n",
    "X_test = scaler.transform(X_test)\n",
    "# fit the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.3f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.300 (3.607)\n"
     ]
    }
   ],
   "source": [
    "# naive data preparation for model evaluation with k-fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# standardize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model using cross-validation\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores)*100, std(scores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.433 (3.471)\n"
     ]
    }
   ],
   "source": [
    "# correct data preparation for model evaluation with k-fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# define the pipeline\n",
    "steps = list()\n",
    "steps.append(('scaler', MinMaxScaler()))\n",
    "steps.append(('model', LogisticRegression()))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model using cross-validation\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores)*100, std(scores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 238\n",
      "1 297\n",
      "2 927\n",
      "3 933\n",
      "4 179\n",
      "5 375\n",
      "6 820\n",
      "7 618\n",
      "8 561\n",
      "9 57\n",
      "10 577\n",
      "11 59\n",
      "12 73\n",
      "13 107\n",
      "14 53\n",
      "15 91\n",
      "16 893\n",
      "17 810\n",
      "18 170\n",
      "19 53\n",
      "20 68\n",
      "21 9\n",
      "22 1\n",
      "23 92\n",
      "24 9\n",
      "25 8\n",
      "26 9\n",
      "27 308\n",
      "28 447\n",
      "29 392\n",
      "30 107\n",
      "31 42\n",
      "32 4\n",
      "33 45\n",
      "34 141\n",
      "35 110\n",
      "36 3\n",
      "37 758\n",
      "38 9\n",
      "39 9\n",
      "40 388\n",
      "41 220\n",
      "42 644\n",
      "43 649\n",
      "44 499\n",
      "45 2\n",
      "46 937\n",
      "47 169\n",
      "48 286\n",
      "49 2\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from numpy import unique\n",
    "\n",
    "data = loadtxt('oil-spill.csv', delimiter=',')\n",
    "# summarize the number of unique values in each column\n",
    "for i in range(data.shape[1]):\n",
    "\tprint(i, len(unique(data[:, i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     238\n",
      "1     297\n",
      "2     927\n",
      "3     933\n",
      "4     179\n",
      "5     375\n",
      "6     820\n",
      "7     618\n",
      "8     561\n",
      "9      57\n",
      "10    577\n",
      "11     59\n",
      "12     73\n",
      "13    107\n",
      "14     53\n",
      "15     91\n",
      "16    893\n",
      "17    810\n",
      "18    170\n",
      "19     53\n",
      "20     68\n",
      "21      9\n",
      "22      1\n",
      "23     92\n",
      "24      9\n",
      "25      8\n",
      "26      9\n",
      "27    308\n",
      "28    447\n",
      "29    392\n",
      "30    107\n",
      "31     42\n",
      "32      4\n",
      "33     45\n",
      "34    141\n",
      "35    110\n",
      "36      3\n",
      "37    758\n",
      "38      9\n",
      "39      9\n",
      "40    388\n",
      "41    220\n",
      "42    644\n",
      "43    649\n",
      "44    499\n",
      "45      2\n",
      "46    937\n",
      "47    169\n",
      "48    286\n",
      "49      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "df = read_csv('oil-spill.csv', header=None)\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 50)\n",
      "[22]\n",
      "(937, 49)\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "df = read_csv('oil-spill.csv', header=None)\n",
    "print(df.shape)\n",
    "# get number of unique values for each column\n",
    "counts = df.nunique()\n",
    "# record columns to delete\n",
    "to_del = [i for i,v in enumerate(counts) if v == 1]\n",
    "print(to_del)\n",
    "# drop useless columns\n",
    "df.drop(to_del, axis=1, inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 238, 25.4%\n",
      "1, 297, 31.7%\n",
      "2, 927, 98.9%\n",
      "3, 933, 99.6%\n",
      "4, 179, 19.1%\n",
      "5, 375, 40.0%\n",
      "6, 820, 87.5%\n",
      "7, 618, 66.0%\n",
      "8, 561, 59.9%\n",
      "9, 57, 6.1%\n",
      "10, 577, 61.6%\n",
      "11, 59, 6.3%\n",
      "12, 73, 7.8%\n",
      "13, 107, 11.4%\n",
      "14, 53, 5.7%\n",
      "15, 91, 9.7%\n",
      "16, 893, 95.3%\n",
      "17, 810, 86.4%\n",
      "18, 170, 18.1%\n",
      "19, 53, 5.7%\n",
      "20, 68, 7.3%\n",
      "21, 9, 1.0%\n",
      "22, 1, 0.1%\n",
      "23, 92, 9.8%\n",
      "24, 9, 1.0%\n",
      "25, 8, 0.9%\n",
      "26, 9, 1.0%\n",
      "27, 308, 32.9%\n",
      "28, 447, 47.7%\n",
      "29, 392, 41.8%\n",
      "30, 107, 11.4%\n",
      "31, 42, 4.5%\n",
      "32, 4, 0.4%\n",
      "33, 45, 4.8%\n",
      "34, 141, 15.0%\n",
      "35, 110, 11.7%\n",
      "36, 3, 0.3%\n",
      "37, 758, 80.9%\n",
      "38, 9, 1.0%\n",
      "39, 9, 1.0%\n",
      "40, 388, 41.4%\n",
      "41, 220, 23.5%\n",
      "42, 644, 68.7%\n",
      "43, 649, 69.3%\n",
      "44, 499, 53.3%\n",
      "45, 2, 0.2%\n",
      "46, 937, 100.0%\n",
      "47, 169, 18.0%\n",
      "48, 286, 30.5%\n",
      "49, 2, 0.2%\n"
     ]
    }
   ],
   "source": [
    "# summarize the percentage of unique values for each column using numpy\n",
    "from numpy import loadtxt\n",
    "from numpy import unique\n",
    "\n",
    "data = loadtxt('oil-spill.csv', delimiter=',')\n",
    "# summarize the number of unique values in each column\n",
    "for i in range(data.shape[1]):\n",
    "\tnum = len(unique(data[:, i]))\n",
    "\tpercentage = float(num) / data.shape[0] * 100\n",
    "\tprint('%d, %d, %.1f%%' % (i, num, percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21, 9, 1.0%\n",
      "22, 1, 0.1%\n",
      "24, 9, 1.0%\n",
      "25, 8, 0.9%\n",
      "26, 9, 1.0%\n",
      "32, 4, 0.4%\n",
      "36, 3, 0.3%\n",
      "38, 9, 1.0%\n",
      "39, 9, 1.0%\n",
      "45, 2, 0.2%\n",
      "49, 2, 0.2%\n"
     ]
    }
   ],
   "source": [
    "# summarize the percentage of unique values for each column using numpy\n",
    "from numpy import loadtxt\n",
    "from numpy import unique\n",
    "# load the dataset\n",
    "data = loadtxt('oil-spill.csv', delimiter=',')\n",
    "# summarize the number of unique values in each column\n",
    "for i in range(data.shape[1]):\n",
    "\tnum = len(unique(data[:, i]))\n",
    "\tpercentage = float(num) / data.shape[0] * 100\n",
    "\tif percentage < 1:\n",
    "\t\tprint('%d, %d, %.1f%%' % (i, num, percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 50)\n",
      "[21, 22, 24, 25, 26, 32, 36, 38, 39, 45, 49]\n",
      "(937, 39)\n"
     ]
    }
   ],
   "source": [
    "# delete columns where number of unique values is less than 1% of the rows\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "df = read_csv('oil-spill.csv', header=None)\n",
    "print(df.shape)\n",
    "# get number of unique values for each column\n",
    "counts = df.nunique()\n",
    "# record columns to delete\n",
    "to_del = [i for i,v in enumerate(counts) if (float(v)/df.shape[0]*100) < 1]\n",
    "print(to_del)\n",
    "# drop useless columns\n",
    "df.drop(to_del, axis=1, inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 49) (937,)\n",
      "(937, 48)\n"
     ]
    }
   ],
   "source": [
    "# example of applying the variance threshold for feature selection\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# load the dataset\n",
    "df = read_csv('oil-spill.csv', header=None)\n",
    "# split data into inputs and outputs\n",
    "data = df.values\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "print(X.shape, y.shape)\n",
    "# define the transform\n",
    "transform = VarianceThreshold()\n",
    "# transform the input data\n",
    "X_sel = transform.fit_transform(X)\n",
    "print(X_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 49) (937,)\n",
      ">Threshold=0.00, Features=48\n",
      ">Threshold=0.05, Features=37\n",
      ">Threshold=0.10, Features=36\n",
      ">Threshold=0.15, Features=35\n",
      ">Threshold=0.20, Features=35\n",
      ">Threshold=0.25, Features=35\n",
      ">Threshold=0.30, Features=35\n",
      ">Threshold=0.35, Features=35\n",
      ">Threshold=0.40, Features=35\n",
      ">Threshold=0.45, Features=33\n",
      ">Threshold=0.50, Features=31\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import arange\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from matplotlib import pyplot\n",
    "\n",
    "df = read_csv('oil-spill.csv', header=None)\n",
    "# split data into inputs and outputs\n",
    "data = df.values\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "print(X.shape, y.shape)\n",
    "# define thresholds to check\n",
    "thresholds = arange(0.0, 0.55, 0.05)\n",
    "# apply transform with each threshold\n",
    "results = list()\n",
    "for t in thresholds:\n",
    "\t# define the transform\n",
    "\ttransform = VarianceThreshold(threshold=t)\n",
    "\t# transform the input data\n",
    "\tX_sel = transform.fit_transform(X)\n",
    "\t# determine the number of input features\n",
    "\tn_features = X_sel.shape[1]\n",
    "\tprint('>Threshold=%.2f, Features=%d' % (t, n_features))\n",
    "\t# store the result\n",
    "\tresults.append(n_features)\n",
    "# plot the threshold vs the number of selected features\n",
    "pyplot.plot(thresholds, results)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "       0    1    2    3          4\n",
      "143  5.8  2.7  5.1  1.9  Virginica\n"
     ]
    }
   ],
   "source": [
    "# locate rows of duplicate data\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "df = read_csv('iris.csv', header=None)\n",
    "# calculate duplicates\n",
    "dups = df.duplicated()\n",
    "# report if there are any duplicates\n",
    "print(dups.any())\n",
    "# list all duplicate rows\n",
    "print(df[dups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 5)\n",
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "# delete rows of duplicate data from the dataset\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "df = read_csv('iris.csv', header=None)\n",
    "print(df.shape)\n",
    "# delete duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=50.049 stdv=4.994\n"
     ]
    }
   ],
   "source": [
    "# generate gaussian data\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = 5 * randn(10000) + 50\n",
    "# summarize\n",
    "print('mean=%.3f stdv=%.3f' % (mean(data), std(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified outliers: 29\n",
      "Non-outlier observations: 9971\n"
     ]
    }
   ],
   "source": [
    "# identify outliers with standard deviation\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = 5 * randn(10000) + 50\n",
    "# calculate summary statistics\n",
    "data_mean, data_std = mean(data), std(data)\n",
    "# define outliers\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "# identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print('Identified outliers: %d' % len(outliers))\n",
    "# remove outliers\n",
    "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "print('Non-outlier observations: %d' % len(outliers_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles: 25th=46.685, 75th=53.359, IQR=6.674\n",
      "Identified outliers: 81\n",
      "Non-outlier observations: 9919\n"
     ]
    }
   ],
   "source": [
    "# identify outliers with interquartile range\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import percentile\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = 5 * randn(10000) + 50\n",
    "# calculate interquartile range\n",
    "q25, q75 = percentile(data, 25), percentile(data, 75)\n",
    "iqr = q75 - q25\n",
    "print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n",
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 1.5\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "# identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print('Identified outliers: %d' % len(outliers))\n",
    "# remove outliers\n",
    "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "print('Non-outlier observations: %d' % len(outliers_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "# Load dataset from SciKit-Learn\n",
    "boston = load_boston()\n",
    "\n",
    "# Create variable data to house data in a Pandas dataframe\n",
    "data = pd.DataFrame(boston.data)\n",
    "\n",
    "# Assign columns in dataframe to names in SciKit-Learns dataset\n",
    "data.columns = boston.feature_names\n",
    "\n",
    "# Assign the PRICE attribute as the target variable\n",
    "data['PRICE'] = boston.target\n",
    "\n",
    "data=data.values\n",
    "#Assign the X and y varibles\n",
    "X, y = data[:,:-1],data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "(339, 13) (167, 13) (339,) (167,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.417\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 13) (305,)\n",
      "MAE: 3.356\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "\n",
    "mask = yhat != -1\n",
    "        \n",
    "X_train, y_train = X_train[mask, :], y_train[mask]\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1   2   3    4     5      6   7  8\n",
      "0     6  148  72  35    0  33.6  0.627  50  1\n",
      "1     1   85  66  29    0  26.6  0.351  31  0\n",
      "2     8  183  64   0    0  23.3  0.672  32  1\n",
      "3     1   89  66  23   94  28.1  0.167  21  0\n",
      "4     0  137  40  35  168  43.1  2.288  33  1\n",
      "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
      "763  10  101  76  48  180  32.9  0.171  63  0\n",
      "764   2  122  70  27    0  36.8  0.340  27  0\n",
      "765   5  121  72  23  112  26.2  0.245  30  0\n",
      "766   1  126  60   0    0  30.1  0.349  47  1\n",
      "767   1   93  70  31    0  30.4  0.315  23  0\n",
      "\n",
      "[768 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# load and summarize the dataset\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# summarize the dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0           1           2           3           4           5  \\\n",
      "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
      "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
      "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
      "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
      "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
      "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
      "\n",
      "                6           7           8  \n",
      "count  768.000000  768.000000  768.000000  \n",
      "mean     0.471876   33.240885    0.348958  \n",
      "std      0.331329   11.760232    0.476951  \n",
      "min      0.078000   21.000000    0.000000  \n",
      "25%      0.243750   24.000000    0.000000  \n",
      "50%      0.372500   29.000000    0.000000  \n",
      "75%      0.626250   41.000000    1.000000  \n",
      "max      2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# load and summarize the dataset\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# summarize the dataset\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1   2   3    4     5      6   7  8\n",
      "0    6  148  72  35    0  33.6  0.627  50  1\n",
      "1    1   85  66  29    0  26.6  0.351  31  0\n",
      "2    8  183  64   0    0  23.3  0.672  32  1\n",
      "3    1   89  66  23   94  28.1  0.167  21  0\n",
      "4    0  137  40  35  168  43.1  2.288  33  1\n",
      "5    5  116  74   0    0  25.6  0.201  30  0\n",
      "6    3   78  50  32   88  31.0  0.248  26  1\n",
      "7   10  115   0   0    0  35.3  0.134  29  0\n",
      "8    2  197  70  45  543  30.5  0.158  53  1\n",
      "9    8  125  96   0    0   0.0  0.232  54  1\n",
      "10   4  110  92   0    0  37.6  0.191  30  0\n",
      "11  10  168  74   0    0  38.0  0.537  34  1\n",
      "12  10  139  80   0    0  27.1  1.441  57  0\n",
      "13   1  189  60  23  846  30.1  0.398  59  1\n",
      "14   5  166  72  19  175  25.8  0.587  51  1\n",
      "15   7  100   0   0    0  30.0  0.484  32  1\n",
      "16   0  118  84  47  230  45.8  0.551  31  1\n",
      "17   7  107  74   0    0  29.6  0.254  31  1\n",
      "18   1  103  30  38   83  43.3  0.183  33  0\n",
      "19   1  115  70  30   96  34.6  0.529  32  1\n"
     ]
    }
   ],
   "source": [
    "# load the dataset and review rows\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# summarize the first 20 rows of data\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# example of summarizing the number of missing values for each variable\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# count the number of missing values for each column\n",
    "num_missing = (dataset[[1,2,3,4,5]] == 0).sum()\n",
    "# report the results\n",
    "print(num_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# example of marking missing values with nan values\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# count the number of nan values in each column\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0      1     2     3      4     5      6   7  8\n",
      "0    6  148.0  72.0  35.0    NaN  33.6  0.627  50  1\n",
      "1    1   85.0  66.0  29.0    NaN  26.6  0.351  31  0\n",
      "2    8  183.0  64.0   NaN    NaN  23.3  0.672  32  1\n",
      "3    1   89.0  66.0  23.0   94.0  28.1  0.167  21  0\n",
      "4    0  137.0  40.0  35.0  168.0  43.1  2.288  33  1\n",
      "5    5  116.0  74.0   NaN    NaN  25.6  0.201  30  0\n",
      "6    3   78.0  50.0  32.0   88.0  31.0  0.248  26  1\n",
      "7   10  115.0   NaN   NaN    NaN  35.3  0.134  29  0\n",
      "8    2  197.0  70.0  45.0  543.0  30.5  0.158  53  1\n",
      "9    8  125.0  96.0   NaN    NaN   NaN  0.232  54  1\n",
      "10   4  110.0  92.0   NaN    NaN  37.6  0.191  30  0\n",
      "11  10  168.0  74.0   NaN    NaN  38.0  0.537  34  1\n",
      "12  10  139.0  80.0   NaN    NaN  27.1  1.441  57  0\n",
      "13   1  189.0  60.0  23.0  846.0  30.1  0.398  59  1\n",
      "14   5  166.0  72.0  19.0  175.0  25.8  0.587  51  1\n",
      "15   7  100.0   NaN   NaN    NaN  30.0  0.484  32  1\n",
      "16   0  118.0  84.0  47.0  230.0  45.8  0.551  31  1\n",
      "17   7  107.0  74.0   NaN    NaN  29.6  0.254  31  1\n",
      "18   1  103.0  30.0  38.0   83.0  43.3  0.183  33  0\n",
      "19   1  115.0  70.0  30.0   96.0  34.6  0.529  32  1\n"
     ]
    }
   ],
   "source": [
    "# example of review data with missing values marked with a nan\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# summarize the first 20 rows of data\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/discriminant_analysis.py\", line 509, in fit\n",
      "    dtype=[np.float64, np.float32])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 821, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 664, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 106, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/discriminant_analysis.py\", line 509, in fit\n",
      "    dtype=[np.float64, np.float32])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 821, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 664, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 106, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/discriminant_analysis.py\", line 509, in fit\n",
      "    dtype=[np.float64, np.float32])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 821, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 664, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 106, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "# example where missing values cause errors\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# split dataset into inputs and outputs\n",
    "values = dataset.values\n",
    "X = values[:,0:8]\n",
    "y = values[:,8]\n",
    "# define the model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define the model evaluation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# evaluate the model\n",
    "result = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "# report the mean performance\n",
    "print('Accuracy: %.3f' % result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "# example of removing rows that contain missing values\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# summarize the shape of the raw data\n",
    "print(dataset.shape)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# drop rows with missing values\n",
    "dataset.dropna(inplace=True)\n",
    "# summarize the shape of the data with missing rows removed\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.781\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on data after rows with missing data are removed\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# drop rows with missing values\n",
    "dataset.dropna(inplace=True)\n",
    "# split dataset into inputs and outputs\n",
    "values = dataset.values\n",
    "X = values[:,0:8]\n",
    "y = values[:,8]\n",
    "# define the model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define the model evaluation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# evaluate the model\n",
    "result = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "# report the mean performance\n",
    "print('Accuracy: %.3f' % result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  surgery  Age  Hospital Number rectal temperature pulse respiratory rate  \\\n",
      "0       2    1           530101               38.5    66               28   \n",
      "1       1    1           534817               39.2    88               20   \n",
      "2       2    1           530334               38.3    40               24   \n",
      "3       1    9          5290409               39.1   164               84   \n",
      "4       2    1           530255               37.3   104               35   \n",
      "\n",
      "  temperature of extremities peripheral pulse mucous membranes  \\\n",
      "0                          3                3                ?   \n",
      "1                          ?                ?                4   \n",
      "2                          1                1                3   \n",
      "3                          4                1                6   \n",
      "4                          ?                ?                6   \n",
      "\n",
      "  capillary refill time  ... packed cell volume total protein  \\\n",
      "0                     2  ...                 45           8.4   \n",
      "1                     1  ...                 50            85   \n",
      "2                     1  ...                 33           6.7   \n",
      "3                     2  ...                 48           7.2   \n",
      "4                     2  ...                 74           7.4   \n",
      "\n",
      "  abdominocentesis appearance abdomcentesis total protein outcome  \\\n",
      "0                           ?                           ?       2   \n",
      "1                           2                           2       3   \n",
      "2                           ?                           ?       1   \n",
      "3                           3                         5.3       2   \n",
      "4                           ?                           ?       2   \n",
      "\n",
      "  surgical lesion type of lesion 1 type of lesion 2 type of lesion 3 cp_data  \n",
      "0               2            11300                0                0       2  \n",
      "1               2             2208                0                0       2  \n",
      "2               2                0                0                0       1  \n",
      "3               1             2208                0                0       1  \n",
      "4               2             4300                0                0       2  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# summarize the horse colic dataset\n",
    "from pandas import read_csv\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv')\n",
    "# summarize the first few rows\n",
    "print(dataframe.head())\n",
    "#print(dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0    1                2                   3      4                 5   \\\n",
      "0  surgery  Age  Hospital Number  rectal temperature  pulse  respiratory rate   \n",
      "1        2    1           530101                38.5     66                28   \n",
      "2        1    1           534817                39.2     88                20   \n",
      "3        2    1           530334                38.3     40                24   \n",
      "4        1    9          5290409                39.1    164                84   \n",
      "\n",
      "                           6                 7                 8   \\\n",
      "0  temperature of extremities  peripheral pulse  mucous membranes   \n",
      "1                           3                 3               NaN   \n",
      "2                         NaN               NaN                 4   \n",
      "3                           1                 1                 3   \n",
      "4                           4                 1                 6   \n",
      "\n",
      "                      9   ...                  18             19  \\\n",
      "0  capillary refill time  ...  packed cell volume  total protein   \n",
      "1                      2  ...                  45            8.4   \n",
      "2                      1  ...                  50             85   \n",
      "3                      1  ...                  33            6.7   \n",
      "4                      2  ...                  48            7.2   \n",
      "\n",
      "                            20                           21       22  \\\n",
      "0  abdominocentesis appearance  abdomcentesis total protein  outcome   \n",
      "1                          NaN                          NaN        2   \n",
      "2                            2                            2        3   \n",
      "3                          NaN                          NaN        1   \n",
      "4                            3                          5.3        2   \n",
      "\n",
      "                23                24                25                26  \\\n",
      "0  surgical lesion  type of lesion 1  type of lesion 2  type of lesion 3   \n",
      "1                2             11300                 0                 0   \n",
      "2                2              2208                 0                 0   \n",
      "3                2                 0                 0                 0   \n",
      "4                1              2208                 0                 0   \n",
      "\n",
      "        27  \n",
      "0  cp_data  \n",
      "1        2  \n",
      "2        2  \n",
      "3        1  \n",
      "4        1  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "> 0, Missing: 1 (0.3%)\n",
      "> 1, Missing: 0 (0.0%)\n",
      "> 2, Missing: 0 (0.0%)\n",
      "> 3, Missing: 60 (19.9%)\n",
      "> 4, Missing: 24 (8.0%)\n",
      "> 5, Missing: 58 (19.3%)\n",
      "> 6, Missing: 56 (18.6%)\n",
      "> 7, Missing: 69 (22.9%)\n",
      "> 8, Missing: 47 (15.6%)\n",
      "> 9, Missing: 32 (10.6%)\n",
      "> 10, Missing: 55 (18.3%)\n",
      "> 11, Missing: 44 (14.6%)\n",
      "> 12, Missing: 56 (18.6%)\n",
      "> 13, Missing: 104 (34.6%)\n",
      "> 14, Missing: 106 (35.2%)\n",
      "> 15, Missing: 247 (82.1%)\n",
      "> 16, Missing: 102 (33.9%)\n",
      "> 17, Missing: 118 (39.2%)\n",
      "> 18, Missing: 29 (9.6%)\n",
      "> 19, Missing: 33 (11.0%)\n",
      "> 20, Missing: 165 (54.8%)\n",
      "> 21, Missing: 198 (65.8%)\n",
      "> 22, Missing: 1 (0.3%)\n",
      "> 23, Missing: 0 (0.0%)\n",
      "> 24, Missing: 0 (0.0%)\n",
      "> 25, Missing: 0 (0.0%)\n",
      "> 26, Missing: 0 (0.0%)\n",
      "> 27, Missing: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# summarize the horse colic dataset\n",
    "from pandas import read_csv\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# summarize the first few rows\n",
    "print(dataframe.head())\n",
    "# summarize the number of rows with missing values for each column\n",
    "for i in range(dataframe.shape[1]):\n",
    "# count number of rows with missing values\n",
    "    n_miss = dataframe[[i]].isnull().sum()\n",
    "    perc = n_miss / dataframe.shape[0] * 100\n",
    "    print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 1605\n",
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "# statistical imputation transform for the horse colic dataset\n",
    "from numpy import isnan\n",
    "from pandas import read_csv\n",
    "from sklearn.impute import SimpleImputer\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[1:, ix], data[1:, 23]\n",
    "X=X.astype('float')\n",
    "# summarize total missing\n",
    "print('Missing: %d' % sum(isnan(X).flatten()))\n",
    "# define imputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "# fit on the dataset\n",
    "imputer.fit(X)\n",
    "# transform the dataset\n",
    "Xtrans = imputer.transform(X)\n",
    "# summarize total missing\n",
    "print('Missing: %d' % sum(isnan(Xtrans).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.868 (0.055)\n"
     ]
    }
   ],
   "source": [
    "# evaluate mean imputation and random forest for the horse colic dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[1:, ix], data[1:, 23]\n",
    "# define modeling pipeline\n",
    "model = RandomForestClassifier()\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', model)])\n",
    "# define model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">mean 0.864 (0.060)\n",
      ">median 0.873 (0.057)\n",
      ">most_frequent 0.866 (0.056)\n",
      ">constant 0.876 (0.052)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare statistical imputation strategies for the horse colic dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "#url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/horse-colic.csv'\n",
    "#dataframe = read_csv(url, header=None, na_values='?')\n",
    "dataframe=read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[1:, ix], data[1:, 23]\n",
    "# evaluate each strategy on the dataset\n",
    "results = list()\n",
    "strategies = ['mean', 'median', 'most_frequent']\n",
    "for s in strategies:\n",
    "\t# create the modeling pipeline\n",
    "\tpipeline = Pipeline(steps=[('i', SimpleImputer(strategy=s)), ('m', RandomForestClassifier())])\n",
    "\t# evaluate the model\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\t# store results\n",
    "\tresults.append(scores)\n",
    "\tprint('>%s %.3f (%.3f)' % (s, mean(scores), std(scores)))\n",
    "    \n",
    "# plot model performance for comparison\n",
    "from numpy import isnan\n",
    "imputer = SimpleImputer(strategy='constant')\n",
    "imputer.fit(X)\n",
    "X= imputer.transform(X)\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        if(X[i,j]=='missing_value'):\n",
    "            X[i,j]=0\n",
    "model=RandomForestClassifier()\n",
    "scores2=cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('>constant %.3f (%.3f)' % (mean(scores2), std(scores2)))\n",
    "results.append(scores2)\n",
    "\n",
    "strategies = ['mean', 'median', 'most_frequent', 'constant']\n",
    "pyplot.boxplot(results, labels=strategies, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 2\n"
     ]
    }
   ],
   "source": [
    "# constant imputation strategy and prediction for the hose colic dataset\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "# load dataset\n",
    "#url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/horse-colic.csv'\n",
    "#dataframe = read_csv(url, header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[1:, ix], data[1:, 23]\n",
    "# create the modeling pipeline\n",
    "#pipeline = Pipeline(steps=[('i', SimpleImputer(strategy='constant')), ('m', RandomForestClassifier())])\n",
    "# fit the model\n",
    "from numpy import isnan\n",
    "imputer = SimpleImputer(strategy='constant')\n",
    "imputer.fit(X)\n",
    "X= imputer.transform(X)\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        if(X[i,j]=='missing_value'):\n",
    "            X[i,j]=0\n",
    "model=RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "# define new data\n",
    "row = [2, 1, 530101, 38.50, 66, 28, 3, 3, nan, 2, 5, 4, 4, nan, nan, nan, 3, 5, 45.00, 8.40, nan, nan, 2, 11300, 00000, 00000, 2]\n",
    "# make a prediction\n",
    "imputer = SimpleImputer(strategy='constant')\n",
    "imputer.fit([row])\n",
    "row=imputer.transform([row])\n",
    "\n",
    "yhat = model.predict(row)\n",
    "#print(row)\n",
    "# summarize prediction\n",
    "print('Predicted Class: %s' % yhat[0])\n",
    "#yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0    1                2                   3      4                 5   \\\n",
      "0  surgery  Age  Hospital Number  rectal temperature  pulse  respiratory rate   \n",
      "1        2    1           530101                38.5     66                28   \n",
      "2        1    1           534817                39.2     88                20   \n",
      "3        2    1           530334                38.3     40                24   \n",
      "4        1    9          5290409                39.1    164                84   \n",
      "\n",
      "                           6                 7                 8   \\\n",
      "0  temperature of extremities  peripheral pulse  mucous membranes   \n",
      "1                           3                 3                 ?   \n",
      "2                           ?                 ?                 4   \n",
      "3                           1                 1                 3   \n",
      "4                           4                 1                 6   \n",
      "\n",
      "                      9   ...                  18             19  \\\n",
      "0  capillary refill time  ...  packed cell volume  total protein   \n",
      "1                      2  ...                  45            8.4   \n",
      "2                      1  ...                  50             85   \n",
      "3                      1  ...                  33            6.7   \n",
      "4                      2  ...                  48            7.2   \n",
      "\n",
      "                            20                           21       22  \\\n",
      "0  abdominocentesis appearance  abdomcentesis total protein  outcome   \n",
      "1                            ?                            ?        2   \n",
      "2                            2                            2        3   \n",
      "3                            ?                            ?        1   \n",
      "4                            3                          5.3        2   \n",
      "\n",
      "                23                24                25                26  \\\n",
      "0  surgical lesion  type of lesion 1  type of lesion 2  type of lesion 3   \n",
      "1                2             11300                 0                 0   \n",
      "2                2              2208                 0                 0   \n",
      "3                2                 0                 0                 0   \n",
      "4                1              2208                 0                 0   \n",
      "\n",
      "        27  \n",
      "0  cp_data  \n",
      "1        2  \n",
      "2        2  \n",
      "3        1  \n",
      "4        1  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# summarize the horse colic dataset\n",
    "from pandas import read_csv\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None)\n",
    "# summarize the first few rows\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0    1                2                   3      4                 5   \\\n",
      "0  surgery  Age  Hospital Number  rectal temperature  pulse  respiratory rate   \n",
      "1        2    1           530101                38.5     66                28   \n",
      "2        1    1           534817                39.2     88                20   \n",
      "3        2    1           530334                38.3     40                24   \n",
      "4        1    9          5290409                39.1    164                84   \n",
      "\n",
      "                           6                 7                 8   \\\n",
      "0  temperature of extremities  peripheral pulse  mucous membranes   \n",
      "1                           3                 3               NaN   \n",
      "2                         NaN               NaN                 4   \n",
      "3                           1                 1                 3   \n",
      "4                           4                 1                 6   \n",
      "\n",
      "                      9   ...                  18             19  \\\n",
      "0  capillary refill time  ...  packed cell volume  total protein   \n",
      "1                      2  ...                  45            8.4   \n",
      "2                      1  ...                  50             85   \n",
      "3                      1  ...                  33            6.7   \n",
      "4                      2  ...                  48            7.2   \n",
      "\n",
      "                            20                           21       22  \\\n",
      "0  abdominocentesis appearance  abdomcentesis total protein  outcome   \n",
      "1                          NaN                          NaN        2   \n",
      "2                            2                            2        3   \n",
      "3                          NaN                          NaN        1   \n",
      "4                            3                          5.3        2   \n",
      "\n",
      "                23                24                25                26  \\\n",
      "0  surgical lesion  type of lesion 1  type of lesion 2  type of lesion 3   \n",
      "1                2             11300                 0                 0   \n",
      "2                2              2208                 0                 0   \n",
      "3                2                 0                 0                 0   \n",
      "4                1              2208                 0                 0   \n",
      "\n",
      "        27  \n",
      "0  cp_data  \n",
      "1        2  \n",
      "2        2  \n",
      "3        1  \n",
      "4        1  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "> 0, Missing: 1 (0.3%)\n",
      "> 1, Missing: 0 (0.0%)\n",
      "> 2, Missing: 0 (0.0%)\n",
      "> 3, Missing: 60 (19.9%)\n",
      "> 4, Missing: 24 (8.0%)\n",
      "> 5, Missing: 58 (19.3%)\n",
      "> 6, Missing: 56 (18.6%)\n",
      "> 7, Missing: 69 (22.9%)\n",
      "> 8, Missing: 47 (15.6%)\n",
      "> 9, Missing: 32 (10.6%)\n",
      "> 10, Missing: 55 (18.3%)\n",
      "> 11, Missing: 44 (14.6%)\n",
      "> 12, Missing: 56 (18.6%)\n",
      "> 13, Missing: 104 (34.6%)\n",
      "> 14, Missing: 106 (35.2%)\n",
      "> 15, Missing: 247 (82.1%)\n",
      "> 16, Missing: 102 (33.9%)\n",
      "> 17, Missing: 118 (39.2%)\n",
      "> 18, Missing: 29 (9.6%)\n",
      "> 19, Missing: 33 (11.0%)\n",
      "> 20, Missing: 165 (54.8%)\n",
      "> 21, Missing: 198 (65.8%)\n",
      "> 22, Missing: 1 (0.3%)\n",
      "> 23, Missing: 0 (0.0%)\n",
      "> 24, Missing: 0 (0.0%)\n",
      "> 25, Missing: 0 (0.0%)\n",
      "> 26, Missing: 0 (0.0%)\n",
      "> 27, Missing: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# summarize the horse colic dataset\n",
    "from pandas import read_csv\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv',header=None, na_values='?')\n",
    "# summarize the first few rows\n",
    "print(dataframe.head())\n",
    "# summarize the number of rows with missing values for each column\n",
    "for i in range(dataframe.shape[1]):\n",
    "# count number of rows with missing values\n",
    "    n_miss = dataframe[[i]].isnull().sum()\n",
    "    perc = n_miss / dataframe.shape[0] * 100\n",
    "    print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 1605\n",
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "# knn imputation transform for the horse colic dataset\n",
    "from numpy import isnan\n",
    "from pandas import read_csv\n",
    "from sklearn.impute import KNNImputer\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[1:, ix], data[1:, 23]\n",
    "X=X.astype('float')\n",
    "# summarize total missing\n",
    "print('Missing: %d' % sum(isnan(X).flatten()))\n",
    "# define imputer\n",
    "imputer = KNNImputer()\n",
    "# fit on the dataset\n",
    "imputer.fit(X)\n",
    "# transform the dataset\n",
    "Xtrans = imputer.transform(X)\n",
    "# summarize total missing\n",
    "print('Missing: %d' % sum(isnan(Xtrans).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy:0.87,  Std:0.06\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "#url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/horse-colic.csv'\n",
    "#dataframe = read_csv(url, header=None, na_values='?')\n",
    "dataframe=read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[1:, ix], data[1:, 23]\n",
    "# evaluate each strategy on the dataset\n",
    "pipeline = Pipeline(steps=[('i', KNNImputer()), ('m', RandomForestClassifier())])\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Mean accuracy:%.2f,  Std:%.2f'%(mean(scores),std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.863 (0.055)\n",
      ">3 0.866 (0.055)\n",
      ">5 0.867 (0.058)\n",
      ">7 0.864 (0.050)\n",
      ">9 0.860 (0.057)\n",
      ">15 0.861 (0.054)\n",
      ">18 0.860 (0.055)\n",
      ">21 0.859 (0.055)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = list()\n",
    "strategies = [str(i) for i in [1,3,5,7,9,15,18,21]]\n",
    "for s in strategies:\n",
    "    # create the modeling pipeline\n",
    "\tpipeline = Pipeline(steps=[('i', KNNImputer(n_neighbors=int(s))), ('m', RandomForestClassifier())])\n",
    "\t# evaluate the model\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\t# store results\n",
    "\tresults.append(scores)\n",
    "\tprint('>%s %.3f (%.3f)' % (s, mean(scores), std(scores)))\n",
    "\n",
    "pyplot.boxplot(results,labels=strategies,showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 1605\n",
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "# iterative imputation transform for the horse colic dataset\n",
    "from numpy import isnan\n",
    "from pandas import read_csv\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "# load dataset\n",
    "\n",
    "dataframe=read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[1:, ix], data[1:, 23]\n",
    "X=X.astype('float')\n",
    "# print total missing\n",
    "print('Missing: %d' % sum(isnan(X).flatten()))\n",
    "# define imputer\n",
    "imputer = IterativeImputer()\n",
    "#imputer=IterativeImputer(estimator=BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n",
    "# fit on the dataset\n",
    "imputer.fit(X)\n",
    "# transform the dataset\n",
    "Xtrans = imputer.transform(X)\n",
    "# print total missing\n",
    "print('Missing: %d' % sum(isnan(Xtrans).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.876 (0.050)\n"
     ]
    }
   ],
   "source": [
    "# evaluate iterative imputation and random forest for the horse colic dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[1:, ix], data[1:, 23]\n",
    "# define modeling pipeline\n",
    "model = RandomForestClassifier()\n",
    "imputer = IterativeImputer()\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', model)])\n",
    "# define model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.871 (0.051)\n",
      ">2 0.872 (0.046)\n",
      ">3 0.869 (0.049)\n",
      ">4 0.872 (0.051)\n",
      ">5 0.871 (0.051)\n",
      ">6 0.869 (0.053)\n",
      ">7 0.873 (0.049)\n",
      ">8 0.864 (0.051)\n",
      ">9 0.869 (0.049)\n",
      ">10 0.870 (0.051)\n",
      ">11 0.872 (0.050)\n",
      ">12 0.869 (0.052)\n",
      ">13 0.869 (0.052)\n",
      ">14 0.879 (0.056)\n",
      ">15 0.867 (0.047)\n",
      ">16 0.868 (0.050)\n",
      ">17 0.872 (0.052)\n",
      ">18 0.867 (0.052)\n",
      ">19 0.869 (0.047)\n",
      ">20 0.869 (0.053)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = list()\n",
    "strategies = [str(i) for i in range(1, 21)]\n",
    "for s in strategies:\n",
    "\t# create the modeling pipeline\n",
    "\tpipeline = Pipeline(steps=[('i', IterativeImputer(max_iter=int(s))), ('m', RandomForestClassifier())])\n",
    "\t# evaluate the model\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\t# store results\n",
    "\tresults.append(scores)\n",
    "\tprint('>%s %.3f (%.3f)' % (s, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=strategies, showmeans=True)\n",
    "pyplot.xticks(rotation=45)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['1'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "X, y = data[1:, :-1], data[1:, -1]\n",
    "\n",
    "# create the modeling pipeline\n",
    "pipeline = Pipeline(steps=[('i', IterativeImputer()), ('m', RandomForestClassifier())])\n",
    "\n",
    "# fit the model\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# define new data\n",
    "row = [2, 1, 530101, 38.50, 66, 28, 3, 3, nan, 2, 5, 4, 4, nan, nan, nan, 3, 5, 45.00, 8.40, nan, nan, 2, 11300, 00000, 00000, 2]\n",
    "\n",
    "# make a prediction\n",
    "\n",
    "yhat = pipeline.predict([row])\n",
    "\n",
    "# summarize prediction\n",
    "print('Predicted Class: %s' % yhat[0])\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (191, 9) (191,)\n",
      "Test (95, 9) (95,)\n"
     ]
    }
   ],
   "source": [
    "# load and summarize the dataset\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset\n",
    "\tdata = read_csv(filename)#, header=None)\n",
    "\trow=data[data.age=='20-29']\n",
    "\tdata.drop(data.index[row.index])        \n",
    "\t# retrieve array\n",
    "\tdataset = data.values\n",
    "\t# split into input and output variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\t# format all fields as string\n",
    "\tX = X.astype(str)\n",
    "\treturn X, y\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_dataset('breast-cancer.csv')\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=1)\n",
    "\n",
    "# summarize\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (191, 9) (191,)\n",
      "Test (95, 9) (95,)\n"
     ]
    }
   ],
   "source": [
    "# example of loading and preparing the breast cancer dataset\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset\n",
    "\tdata = read_csv(filename)#, header=None)\n",
    "\trow=data[data.age=='20-29']\n",
    "\tdata.drop(data.index[row.index]) \n",
    "\t# retrieve array\n",
    "\tdataset = data.values\n",
    "\t# split into input and output variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\t# format all fields as string\n",
    "\tX = X.astype(str)\n",
    "\treturn X, y\n",
    "\n",
    "# prepare input data\n",
    "def prepare_inputs(X_train, X_test):\n",
    "\toe = OrdinalEncoder()\n",
    "\toe.fit(X_train)\n",
    "\tX_train_enc = oe.transform(X_train)\n",
    "\tX_test_enc = oe.transform(X_test)\n",
    "\treturn X_train_enc, X_test_enc\n",
    "\n",
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\treturn y_train_enc, y_test_enc\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_dataset('breast-cancer.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# prepare input data\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
    "# summarize\n",
    "print('Train', X_train_enc.shape, y_train_enc.shape)\n",
    "print('Test', X_test_enc.shape, y_test_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.472553\n",
      "Feature 1: 0.029193\n",
      "Feature 2: 2.137658\n",
      "Feature 3: 29.381059\n",
      "Feature 4: 0.776891\n",
      "Feature 5: 8.100183\n",
      "Feature 6: 1.273822\n",
      "Feature 7: 0.695321\n",
      "Feature 8: 3.699989\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of chi squared feature selection for categorical data\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tdata = read_csv(filename)#, header=None)\n",
    "\trow=data[data.age=='20-29']\n",
    "\tdata.drop(data.index[row.index]) \n",
    "\t# retrieve numpy array\n",
    "\tdataset = data.values\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\t# format all fields as string\n",
    "\tX = X.astype(str)\n",
    "\treturn X, y\n",
    " \n",
    "# prepare input data\n",
    "def prepare_inputs(X_train, X_test):\n",
    "\toe = OrdinalEncoder()\n",
    "\toe.fit(X_train)\n",
    "\tX_train_enc = oe.transform(X_train)\n",
    "\tX_test_enc = oe.transform(X_test)\n",
    "\treturn X_train_enc, X_test_enc\n",
    " \n",
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\treturn y_train_enc, y_test_enc\n",
    " \n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "\tfs = SelectKBest(score_func=chi2, k='all')\n",
    "\tfs.fit(X_train, y_train)\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs, fs\n",
    " \n",
    "# load the dataset\n",
    "X, y = load_dataset('breast-cancer.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# prepare input data\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.006489\n",
      "Feature 1: 0.008838\n",
      "Feature 2: 0.059047\n",
      "Feature 3: 0.025923\n",
      "Feature 4: 0.016748\n",
      "Feature 5: 0.034663\n",
      "Feature 6: 0.000000\n",
      "Feature 7: 0.051699\n",
      "Feature 8: 0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of mutual information feature selection for categorical data\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tdata = read_csv(filename)#, header=None)\n",
    "\trow=data[data.age=='20-29']\n",
    "\tdata.drop(data.index[row.index]) \n",
    "\t# retrieve numpy array\n",
    "\tdataset = data.values\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\t# format all fields as string\n",
    "\tX = X.astype(str)\n",
    "\treturn X, y\n",
    " \n",
    "# prepare input data\n",
    "def prepare_inputs(X_train, X_test):\n",
    "\toe = OrdinalEncoder()\n",
    "\toe.fit(X_train)\n",
    "\tX_train_enc = oe.transform(X_train)\n",
    "\tX_test_enc = oe.transform(X_test)\n",
    "\treturn X_train_enc, X_test_enc\n",
    " \n",
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\treturn y_train_enc, y_test_enc\n",
    " \n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "\tfs = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "\tfs.fit(X_train, y_train)\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs, fs\n",
    " \n",
    "# load the dataset\n",
    "X, y = load_dataset('breast-cancer.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# prepare input data\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.68\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model using all input features\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tdata = read_csv(filename)#, header=None)\n",
    "\trow=data[data.age=='20-29']\n",
    "\tdata.drop(data.index[row.index])\n",
    "\t# retrieve numpy array\n",
    "\tdataset = data.values\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\t# format all fields as string\n",
    "\tX = X.astype(str)\n",
    "\treturn X, y\n",
    " \n",
    "# prepare input data\n",
    "def prepare_inputs(X_train, X_test):\n",
    "\toe = OrdinalEncoder()\n",
    "\toe.fit(X_train)\n",
    "\tX_train_enc = oe.transform(X_train)\n",
    "\tX_test_enc = oe.transform(X_test)\n",
    "\treturn X_train_enc, X_test_enc\n",
    " \n",
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\treturn y_train_enc, y_test_enc\n",
    " \n",
    "# load the dataset\n",
    "X, y = load_dataset('breast-cancer.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# prepare input data\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_enc, y_train_enc)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_enc)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.84\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model fit using chi squared input features\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tdata = read_csv(filename)#, header=None)\n",
    "\trow=data[data.age=='20-29']\n",
    "\tdata.drop(data.index[row.index])\n",
    "\t# retrieve numpy array\n",
    "\tdataset = data.values\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\t# format all fields as string\n",
    "\tX = X.astype(str)\n",
    "\treturn X, y\n",
    " \n",
    "# prepare input data\n",
    "def prepare_inputs(X_train, X_test):\n",
    "\toe = OrdinalEncoder()\n",
    "\toe.fit(X_train)\n",
    "\tX_train_enc = oe.transform(X_train)\n",
    "\tX_test_enc = oe.transform(X_test)\n",
    "\treturn X_train_enc, X_test_enc\n",
    " \n",
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\treturn y_train_enc, y_test_enc\n",
    " \n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "\tfs = SelectKBest(score_func=chi2, k=4)\n",
    "\tfs.fit(X_train, y_train)\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs\n",
    " \n",
    "# load the dataset\n",
    "X, y = load_dataset('breast-cancer.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# prepare input data\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_fs, y_train_enc)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.84\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model fit using mutual information input features\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tdata = read_csv(filename)#, header=None)\n",
    "\trow=data[data.age=='20-29']\n",
    "\tdata.drop(data.index[row.index])\n",
    "\t# retrieve numpy array\n",
    "\tdataset = data.values\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\t# format all fields as string\n",
    "\tX = X.astype(str)\n",
    "\treturn X, y\n",
    " \n",
    "# prepare input data\n",
    "def prepare_inputs(X_train, X_test):\n",
    "\toe = OrdinalEncoder()\n",
    "\toe.fit(X_train)\n",
    "\tX_train_enc = oe.transform(X_train)\n",
    "\tX_test_enc = oe.transform(X_test)\n",
    "\treturn X_train_enc, X_test_enc\n",
    " \n",
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\treturn y_train_enc, y_test_enc\n",
    " \n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "\tfs = SelectKBest(score_func=mutual_info_classif, k=4)\n",
    "\tfs.fit(X_train, y_train)\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs\n",
    " \n",
    "# load the dataset\n",
    "X, y = load_dataset('breast-cancer.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# prepare input data\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_fs, y_train_enc)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (514, 8) (514,)\n",
      "Test (254, 8) (254,)\n"
     ]
    }
   ],
   "source": [
    "# load and summarize the dataset\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tdata = read_csv(filename, header=None)\n",
    "\t# retrieve numpy array\n",
    "\tdataset = data.values\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\treturn X, y\n",
    " \n",
    "# load the dataset\n",
    "X, y = load_dataset('pima-indians-diabetes.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# summarize\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 16.527385\n",
      "Feature 1: 131.325562\n",
      "Feature 2: 0.042371\n",
      "Feature 3: 1.415216\n",
      "Feature 4: 12.778966\n",
      "Feature 5: 49.209523\n",
      "Feature 6: 13.377142\n",
      "Feature 7: 25.126440\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of anova f-test feature selection for numerical data\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tdata = read_csv(filename, header=None)\n",
    "\t# retrieve numpy array\n",
    "\tdataset = data.values\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\treturn X, y\n",
    " \n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "\t# configure to select all features\n",
    "\tfs = SelectKBest(score_func=f_classif, k='all')\n",
    "\t# learn relationship from training data\n",
    "\tfs.fit(X_train, y_train)\n",
    "\t# transform train input data\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\t# transform test input data\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs, fs\n",
    " \n",
    "# load the dataset\n",
    "X, y = load_dataset('pima-indians-diabetes.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.018945\n",
      "Feature 1: 0.101388\n",
      "Feature 2: 0.012245\n",
      "Feature 3: 0.001590\n",
      "Feature 4: 0.054564\n",
      "Feature 5: 0.080319\n",
      "Feature 6: 0.007367\n",
      "Feature 7: 0.053618\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of mutual information feature selection for categorical data\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tdata = read_csv(filename, header=None)\n",
    "\t# retrieve numpy array\n",
    "\tdataset = data.values\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\t# format all fields as string\n",
    "\tX = X.astype(str)\n",
    "\treturn X, y\n",
    " \n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "\tfs = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "\tfs.fit(X_train, y_train)\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs, fs\n",
    " \n",
    "# load the dataset\n",
    "X, y = load_dataset('pima-indians-diabetes.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# prepare input data\n",
    "#X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "# prepare output data\n",
    "#y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.56\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model using all input features\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    data = read_csv(filename, header=None)\n",
    "    # retrieve numpy array\n",
    "    dataset = data.values\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = dataset[:, :-1]\n",
    "    y = dataset[:,-1]\n",
    "    return X, y\n",
    "# load the dataset\n",
    "X, y = load_dataset('pima-indians-diabetes.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.74\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model using 4 features chosen with anova f-test\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    data = read_csv(filename, header=None)\n",
    "    # retrieve numpy array\n",
    "    dataset = data.values\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = dataset[:, :-1]\n",
    "    y = dataset[:,-1]\n",
    "    return X, y\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=f_classif, k=4)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "# load the dataset\n",
    "X, y = load_dataset('pima-indians-diabetes.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.56\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model using 4 features chosen with mutual information\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    data = read_csv(filename, header=None)\n",
    "    # retrieve numpy array\n",
    "    dataset = data.values\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = dataset[:, :-1]\n",
    "    y = dataset[:,-1]\n",
    "    return X, y\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=4)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "# load the dataset\n",
    "X, y = load_dataset('pima-indians-diabetes.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Accuracy: 0.770\n",
      "Best Config: {'anova__k': 7}\n"
     ]
    }
   ],
   "source": [
    "# compare different numbers of features selected using anova f-test\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    data = read_csv(filename, header=None)\n",
    "    # retrieve numpy array\n",
    "    dataset = data.values\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = dataset[:, :-1]\n",
    "    y = dataset[:,-1]\n",
    "    return X, y\n",
    "# define dataset\n",
    "X, y = load_dataset('pima-indians-diabetes.csv')\n",
    "# define the evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the pipeline to evaluate\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "fs = SelectKBest(score_func=f_classif)\n",
    "pipeline = Pipeline(steps=[('anova',fs), ('lr', model)])\n",
    "# define the grid\n",
    "grid = dict()\n",
    "grid['anova__k'] = [i+1 for i in range(X.shape[1])]\n",
    "# define the grid search\n",
    "search = GridSearchCV(pipeline, grid, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "# perform the search\n",
    "results = search.fit(X, y)\n",
    "# summarize best\n",
    "print('Best Mean Accuracy: %.3f' % results.best_score_)\n",
    "print('Best Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.748 (0.048)\n",
      ">2 0.756 (0.042)\n",
      ">3 0.761 (0.044)\n",
      ">4 0.759 (0.042)\n",
      ">5 0.770 (0.041)\n",
      ">6 0.766 (0.042)\n",
      ">7 0.770 (0.042)\n",
      ">8 0.768 (0.040)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare different numbers of features selected using anova f-test\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    data = read_csv(filename, header=None)\n",
    "    # retrieve numpy array\n",
    "    dataset = data.values\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = dataset[:, :-1]\n",
    "    y = dataset[:,-1]\n",
    "    return X, y\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "# define dataset\n",
    "X, y = load_dataset('pima-indians-diabetes.csv')\n",
    "# define number of features to evaluate\n",
    "num_features = [i+1 for i in range(X.shape[1])]\n",
    "# enumerate each number of features\n",
    "results = list()\n",
    "for k in num_features:\n",
    "    # create pipeline\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    fs = SelectKBest(score_func=f_classif, k=k)\n",
    "    pipeline = Pipeline(steps=[('anova',fs), ('lr', model)])\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(pipeline)\n",
    "    results.append(scores)\n",
    "    # summarize the results\n",
    "    print('>%d %.3f (%.3f)' % (k, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=num_features, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (670, 100) (670,)\n",
      "Test (330, 100) (330,)\n"
     ]
    }
   ],
   "source": [
    "# load and summarize the dataset\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1,\n",
    "    random_state=1)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# summarize\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.009419\n",
      "Feature 1: 1.018881\n",
      "Feature 2: 1.205187\n",
      "Feature 3: 0.000138\n",
      "Feature 4: 0.167511\n",
      "Feature 5: 5.985083\n",
      "Feature 6: 0.062405\n",
      "Feature 7: 1.455257\n",
      "Feature 8: 0.420384\n",
      "Feature 9: 101.392225\n",
      "Feature 10: 0.387091\n",
      "Feature 11: 1.581124\n",
      "Feature 12: 3.014463\n",
      "Feature 13: 0.232705\n",
      "Feature 14: 0.076281\n",
      "Feature 15: 4.299652\n",
      "Feature 16: 1.497530\n",
      "Feature 17: 0.261242\n",
      "Feature 18: 5.960005\n",
      "Feature 19: 0.523219\n",
      "Feature 20: 0.003365\n",
      "Feature 21: 0.024178\n",
      "Feature 22: 0.220958\n",
      "Feature 23: 0.576770\n",
      "Feature 24: 0.627198\n",
      "Feature 25: 0.350687\n",
      "Feature 26: 0.281877\n",
      "Feature 27: 0.584210\n",
      "Feature 28: 52.196337\n",
      "Feature 29: 0.046855\n",
      "Feature 30: 0.147323\n",
      "Feature 31: 0.368485\n",
      "Feature 32: 0.077631\n",
      "Feature 33: 0.698140\n",
      "Feature 34: 45.744046\n",
      "Feature 35: 2.047376\n",
      "Feature 36: 0.786270\n",
      "Feature 37: 0.996190\n",
      "Feature 38: 2.733533\n",
      "Feature 39: 63.957656\n",
      "Feature 40: 231.885540\n",
      "Feature 41: 1.372448\n",
      "Feature 42: 0.581860\n",
      "Feature 43: 1.072930\n",
      "Feature 44: 1.066976\n",
      "Feature 45: 0.344656\n",
      "Feature 46: 13.951551\n",
      "Feature 47: 3.575080\n",
      "Feature 48: 0.007299\n",
      "Feature 49: 0.004651\n",
      "Feature 50: 1.094585\n",
      "Feature 51: 0.241065\n",
      "Feature 52: 0.355137\n",
      "Feature 53: 0.020294\n",
      "Feature 54: 0.154567\n",
      "Feature 55: 2.592512\n",
      "Feature 56: 0.300175\n",
      "Feature 57: 0.357798\n",
      "Feature 58: 3.060090\n",
      "Feature 59: 0.890357\n",
      "Feature 60: 122.132164\n",
      "Feature 61: 2.029982\n",
      "Feature 62: 0.091551\n",
      "Feature 63: 1.081123\n",
      "Feature 64: 0.056041\n",
      "Feature 65: 2.930717\n",
      "Feature 66: 0.054886\n",
      "Feature 67: 1.332787\n",
      "Feature 68: 0.145579\n",
      "Feature 69: 0.986331\n",
      "Feature 70: 0.092661\n",
      "Feature 71: 0.083219\n",
      "Feature 72: 0.198847\n",
      "Feature 73: 2.065792\n",
      "Feature 74: 0.236594\n",
      "Feature 75: 0.512608\n",
      "Feature 76: 1.095650\n",
      "Feature 77: 0.015359\n",
      "Feature 78: 2.193730\n",
      "Feature 79: 1.574530\n",
      "Feature 80: 5.360863\n",
      "Feature 81: 0.041874\n",
      "Feature 82: 5.717705\n",
      "Feature 83: 0.436560\n",
      "Feature 84: 5.594438\n",
      "Feature 85: 0.000065\n",
      "Feature 86: 0.026748\n",
      "Feature 87: 0.408422\n",
      "Feature 88: 2.092557\n",
      "Feature 89: 9.568498\n",
      "Feature 90: 0.642445\n",
      "Feature 91: 0.065794\n",
      "Feature 92: 198.705931\n",
      "Feature 93: 0.073807\n",
      "Feature 94: 1.048605\n",
      "Feature 95: 0.004106\n",
      "Feature 96: 0.042110\n",
      "Feature 97: 0.034228\n",
      "Feature 98: 0.792433\n",
      "Feature 99: 0.015365\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of correlation feature selection for numerical data\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from matplotlib import pyplot\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=f_regression, k='all')\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "# load the dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1,\n",
    "    random_state=1)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.045484\n",
      "Feature 1: 0.000000\n",
      "Feature 2: 0.000000\n",
      "Feature 3: 0.000000\n",
      "Feature 4: 0.024816\n",
      "Feature 5: 0.000000\n",
      "Feature 6: 0.022659\n",
      "Feature 7: 0.000000\n",
      "Feature 8: 0.000000\n",
      "Feature 9: 0.074320\n",
      "Feature 10: 0.000000\n",
      "Feature 11: 0.000000\n",
      "Feature 12: 0.000000\n",
      "Feature 13: 0.000000\n",
      "Feature 14: 0.020390\n",
      "Feature 15: 0.004307\n",
      "Feature 16: 0.000000\n",
      "Feature 17: 0.000000\n",
      "Feature 18: 0.016566\n",
      "Feature 19: 0.003688\n",
      "Feature 20: 0.007579\n",
      "Feature 21: 0.018640\n",
      "Feature 22: 0.025206\n",
      "Feature 23: 0.017967\n",
      "Feature 24: 0.069173\n",
      "Feature 25: 0.000000\n",
      "Feature 26: 0.022232\n",
      "Feature 27: 0.000000\n",
      "Feature 28: 0.007849\n",
      "Feature 29: 0.012849\n",
      "Feature 30: 0.017402\n",
      "Feature 31: 0.008083\n",
      "Feature 32: 0.047321\n",
      "Feature 33: 0.002829\n",
      "Feature 34: 0.028968\n",
      "Feature 35: 0.000000\n",
      "Feature 36: 0.071652\n",
      "Feature 37: 0.027969\n",
      "Feature 38: 0.000000\n",
      "Feature 39: 0.064796\n",
      "Feature 40: 0.137695\n",
      "Feature 41: 0.008732\n",
      "Feature 42: 0.003983\n",
      "Feature 43: 0.000000\n",
      "Feature 44: 0.009387\n",
      "Feature 45: 0.000000\n",
      "Feature 46: 0.038385\n",
      "Feature 47: 0.000000\n",
      "Feature 48: 0.000000\n",
      "Feature 49: 0.000000\n",
      "Feature 50: 0.000000\n",
      "Feature 51: 0.000000\n",
      "Feature 52: 0.000000\n",
      "Feature 53: 0.008130\n",
      "Feature 54: 0.041779\n",
      "Feature 55: 0.000000\n",
      "Feature 56: 0.000000\n",
      "Feature 57: 0.000000\n",
      "Feature 58: 0.031228\n",
      "Feature 59: 0.002689\n",
      "Feature 60: 0.146192\n",
      "Feature 61: 0.000000\n",
      "Feature 62: 0.000000\n",
      "Feature 63: 0.000000\n",
      "Feature 64: 0.018194\n",
      "Feature 65: 0.021368\n",
      "Feature 66: 0.046071\n",
      "Feature 67: 0.034707\n",
      "Feature 68: 0.033530\n",
      "Feature 69: 0.002262\n",
      "Feature 70: 0.018332\n",
      "Feature 71: 0.000000\n",
      "Feature 72: 0.000000\n",
      "Feature 73: 0.074876\n",
      "Feature 74: 0.000000\n",
      "Feature 75: 0.004429\n",
      "Feature 76: 0.002617\n",
      "Feature 77: 0.031354\n",
      "Feature 78: 0.000000\n",
      "Feature 79: 0.000000\n",
      "Feature 80: 0.000000\n",
      "Feature 81: 0.033931\n",
      "Feature 82: 0.010400\n",
      "Feature 83: 0.019373\n",
      "Feature 84: 0.000000\n",
      "Feature 85: 0.033191\n",
      "Feature 86: 0.000000\n",
      "Feature 87: 0.028745\n",
      "Feature 88: 0.000000\n",
      "Feature 89: 0.000000\n",
      "Feature 90: 0.000000\n",
      "Feature 91: 0.017698\n",
      "Feature 92: 0.129797\n",
      "Feature 93: 0.000000\n",
      "Feature 94: 0.002171\n",
      "Feature 95: 0.029995\n",
      "Feature 96: 0.000000\n",
      "Feature 97: 0.014428\n",
      "Feature 98: 0.000000\n",
      "Feature 99: 0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of mutual information feature selection for numerical input data\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from matplotlib import pyplot\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=mutual_info_regression, k='all')\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "# load the dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1,\n",
    "    random_state=1)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.086\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model using all input features\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# load the dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1,\n",
    "    random_state=1)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.740\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model using 10 features chosen with correlation\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=f_regression, k=10)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "# load the dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1,\n",
    "random_state=1)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.085\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model using 88 features chosen with correlation\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=f_regression, k=88)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "# load the dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1,\n",
    "    random_state=1)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.084\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model using 88 features chosen with mutual information\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=mutual_info_regression, k=88)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "# load the dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1,\n",
    "    random_state=1)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE: -0.082\n",
      "Best Config: {'sel__k': 81}\n",
      ">-1.100 with: {'sel__k': 80}\n",
      ">-0.082 with: {'sel__k': 81}\n",
      ">-0.082 with: {'sel__k': 82}\n",
      ">-0.082 with: {'sel__k': 83}\n",
      ">-0.082 with: {'sel__k': 84}\n",
      ">-0.082 with: {'sel__k': 85}\n",
      ">-0.082 with: {'sel__k': 86}\n",
      ">-0.082 with: {'sel__k': 87}\n",
      ">-0.082 with: {'sel__k': 88}\n",
      ">-0.083 with: {'sel__k': 89}\n",
      ">-0.083 with: {'sel__k': 90}\n",
      ">-0.083 with: {'sel__k': 91}\n",
      ">-0.083 with: {'sel__k': 92}\n",
      ">-0.083 with: {'sel__k': 93}\n",
      ">-0.083 with: {'sel__k': 94}\n",
      ">-0.083 with: {'sel__k': 95}\n",
      ">-0.083 with: {'sel__k': 96}\n",
      ">-0.083 with: {'sel__k': 97}\n",
      ">-0.083 with: {'sel__k': 98}\n",
      ">-0.083 with: {'sel__k': 99}\n",
      ">-0.083 with: {'sel__k': 100}\n"
     ]
    }
   ],
   "source": [
    "# compare different numbers of features selected using mutual information\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1,\n",
    "    random_state=1)\n",
    "# define the evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the pipeline to evaluate\n",
    "model = LinearRegression()\n",
    "fs = SelectKBest(score_func=mutual_info_regression)\n",
    "pipeline = Pipeline(steps=[('sel',fs), ('lr', model)])\n",
    "# define the grid\n",
    "grid = dict()\n",
    "grid['sel__k'] = [i for i in range(X.shape[1]-20, X.shape[1]+1)]\n",
    "# define the grid search\n",
    "search = GridSearchCV(pipeline, grid, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv)\n",
    "# perform the search\n",
    "results = search.fit(X, y)\n",
    "# summarize best\n",
    "print('Best MAE: %.3f' % results.best_score_)\n",
    "print('Best Config: %s' % results.best_params_)\n",
    "# summarize all\n",
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print('>%.3f with: %r' % (mean, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">81 -0.082 (0.006)\n",
      ">82 -0.082 (0.006)\n",
      ">83 -0.082 (0.006)\n",
      ">84 -0.082 (0.006)\n",
      ">85 -0.082 (0.006)\n",
      ">86 -0.082 (0.006)\n",
      ">87 -0.082 (0.006)\n",
      ">88 -0.082 (0.006)\n",
      ">89 -0.083 (0.006)\n",
      ">90 -0.083 (0.006)\n",
      ">91 -0.083 (0.006)\n",
      ">92 -0.083 (0.006)\n",
      ">93 -0.083 (0.006)\n",
      ">94 -0.083 (0.006)\n",
      ">95 -0.083 (0.006)\n",
      ">96 -0.083 (0.006)\n",
      ">97 -0.083 (0.006)\n",
      ">98 -0.083 (0.006)\n",
      ">99 -0.083 (0.006)\n",
      ">100 -0.083 (0.006)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare different numbers of features selected using mutual information\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1,\n",
    "    random_state=1)\n",
    "# define number of features to evaluate\n",
    "num_features = [i for i in range(X.shape[1]-19, X.shape[1]+1)]\n",
    "# enumerate each number of features\n",
    "results = list()\n",
    "for k in num_features:\n",
    "    # create pipeline\n",
    "    model = LinearRegression()\n",
    "    fs = SelectKBest(score_func=mutual_info_regression, k=k)\n",
    "    pipeline = Pipeline(steps=[('sel',fs), ('lr', model)])\n",
    "    # evaluate the model\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='neg_mean_absolute_error', cv=cv,\n",
    "    n_jobs=-1)\n",
    "    results.append(scores)\n",
    "    # summarize the results\n",
    "    print('>%d %.3f (%.3f)' % (k, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=num_features, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5,\n",
    "    random_state=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.889,  Std:0.037\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "rfe=RFE(estimator=DecisionTreeClassifier(),n_features_to_select=5)\n",
    "model=DecisionTreeClassifier()\n",
    "pipeline=Pipeline(steps=[('s',rfe),('m',model)])\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1,error_score='raise')\n",
    "print('Accuracy:%.3f,  Std:%.3f'%(mean(n_scores),std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class:1\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X,y)\n",
    "data=[[2.5,-0.13,3.16,-4.36,-1.61,-1.39,-2.49,-1.93,3.26,2.06]]\n",
    "yhat=pipeline.predict(data)\n",
    "print('predicted class:%d'%(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:-27.151,  Std:2.823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "rfe=RFE(estimator=DecisionTreeRegressor(),n_features_to_select=5)\n",
    "model=DecisionTreeRegressor()\n",
    "pipeline=Pipeline(steps=[('s',rfe),('m',model)])\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1,error_score='raise')\n",
    "print('MAE:%.3f,  Std:%.3f'%(mean(n_scores),std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:-84.288\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X,y)\n",
    "data=[[-2.02,0.31,0.83,-0.31,0.16,-1.44,0.88,-0.50,2.06,0.76]]\n",
    "yhat=pipeline.predict(data)\n",
    "print('predicted:%.3f'%(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">2, 0.744 (0.042)\n",
      ">3, 0.816 (0.034)\n",
      ">4, 0.830 (0.039)\n",
      ">5, 0.845 (0.035)\n",
      ">6, 0.859 (0.036)\n",
      ">7, 0.852 (0.036)\n",
      ">8, 0.853 (0.041)\n",
      ">9, 0.846 (0.039)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "    return X,y\n",
    "\n",
    "def get_models():\n",
    "    models=dict()\n",
    "    for i in range(2,10):\n",
    "        rfe=RFE(estimator=DecisionTreeClassifier(),n_features_to_select=i)\n",
    "        model=DecisionTreeClassifier()\n",
    "        models[str(i)]=Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "def evaluate_model(model,X,y):\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1,error_score='raise')\n",
    "    return scores\n",
    "\n",
    "\n",
    "results=list()\n",
    "names=list()\n",
    "X,y=get_dataset()\n",
    "models=get_models()\n",
    "for k in range(2,10):\n",
    "    name=str(k)\n",
    "    model=models[name]\n",
    "    scores=evaluate_model(model,X,y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s, %.3f (%.3f)'%(name,mean(scores),std(scores)))\n",
    "    \n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.845(0.043)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "X,y=make_classification(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "rfe=RFECV(estimator=DecisionTreeClassifier())\n",
    "model=DecisionTreeClassifier()\n",
    "pipeline=Pipeline(steps=[('s',rfe),('m',model)])\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1,error_score='raise')\n",
    "print('Accuracy:%.3f(%.3f)'%(mean(scores),std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column:0, Selected:True, Rank:1.000\n",
      "Column:1, Selected:True, Rank:1.000\n",
      "Column:2, Selected:False, Rank:3.000\n",
      "Column:3, Selected:True, Rank:1.000\n",
      "Column:4, Selected:False, Rank:5.000\n",
      "Column:5, Selected:True, Rank:1.000\n",
      "Column:6, Selected:False, Rank:4.000\n",
      "Column:7, Selected:False, Rank:6.000\n",
      "Column:8, Selected:True, Rank:1.000\n",
      "Column:9, Selected:False, Rank:2.000\n"
     ]
    }
   ],
   "source": [
    "X,y=make_classification(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "rfe=RFE(estimator=DecisionTreeClassifier(),n_features_to_select=5)\n",
    "rfe.fit(X,y)\n",
    "for i in range(X.shape[1]):\n",
    "    print('Column:%d, Selected:%s, Rank:%.3f'%(i,rfe.support_[i],rfe.ranking_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr, 0.800 (0.039)\n",
      ">per, 0.793 (0.055)\n",
      ">cart, 0.848 (0.042)\n",
      ">rf, 0.831 (0.034)\n",
      ">gbm, 0.842 (0.040)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "    return X,y\n",
    "\n",
    "def get_models():\n",
    "    rfe=RFE(estimator=LogisticRegression(),n_features_to_select=5)\n",
    "    model=DecisionTreeClassifier()\n",
    "    models['lr']=Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    \n",
    "    rfe=RFE(estimator=Perceptron(),n_features_to_select=5)\n",
    "    model=DecisionTreeClassifier()\n",
    "    models['per']=Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    \n",
    "    rfe=RFE(estimator=DecisionTreeClassifier(),n_features_to_select=5)\n",
    "    model=DecisionTreeClassifier()\n",
    "    models['cart']=Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    \n",
    "    rfe=RFE(estimator=RandomForestClassifier(),n_features_to_select=5)\n",
    "    model=DecisionTreeClassifier()\n",
    "    models['rf']=Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    \n",
    "    rfe=RFE(estimator=GradientBoostingClassifier(),n_features_to_select=5)\n",
    "    model=DecisionTreeClassifier()\n",
    "    models['gbm']=Pipeline(steps=[('s',rfe),('m',model)]) \n",
    "    \n",
    "    return models\n",
    "\n",
    "def evaluate_model(model,X,y):\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1,error_score='raise')\n",
    "    return scores\n",
    "\n",
    "\n",
    "results=list()\n",
    "names=['lr','per','cart','rf','gbm']\n",
    "X,y=get_dataset()\n",
    "models=get_models()\n",
    "for name in names:\n",
    "    model=models[name]\n",
    "    scores=evaluate_model(model,X,y)\n",
    "    results.append(scores)\n",
    "    print('>%s, %.3f (%.3f)'%(name,mean(scores),std(scores)))\n",
    "    \n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
